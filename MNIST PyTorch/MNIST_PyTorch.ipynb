{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjqYPwFewta-",
        "colab_type": "text"
      },
      "source": [
        "***Importing required libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJUxrmPEH8EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets,transforms\n",
        "from torch import nn\n",
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw75cJLow0zE",
        "colab_type": "text"
      },
      "source": [
        "***Do tranformations(if required) and import dataset***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72yeTAlWJYbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/',download=True,train=True,transform=transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9JShBvAw9Ot",
        "colab_type": "text"
      },
      "source": [
        "***Defining model architecture***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlNkb4PWQxAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784 , 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(256 , 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128 , 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64 , 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters() , lr = 0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwRZ8BDfxD0C",
        "colab_type": "text"
      },
      "source": [
        "***Training the neural network and printing loss***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvhfUA4RRK4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5\n",
        "for i in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images , labels in trainloader:\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    images = images.view(images.shape[0],-1)\n",
        "    \n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}